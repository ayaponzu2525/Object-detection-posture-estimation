import cv2
import os
from ultralytics import YOLO


# å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã€ç‰©ä½“æ¤œå‡ºã‚’è¡Œã„ã€ä¸€ç•ªå¤§ãã„äººç‰©ã®éƒ¨åˆ†ã‚’ï¼”åˆ†å‰²ã™ã‚‹

# === è¨­å®š ===
VIDEO_PATH = r"C:\Users\ayapo\Documents\hightech_local\Object-detection-posture-estimation\movie\drink_water.mp4"
OUTPUT_DIR = r"C:\Users\ayapo\Documents\hightech_local\Object-detection-posture-estimation\movie\frames_3"
YOLO_MODEL_PATH = "yolov8s.pt"  # ä½¿ç”¨ã™ã‚‹YOLOãƒ¢ãƒ‡ãƒ«
TARGET_CLASS = "person"  # æ¤œå‡ºå¯¾è±¡ã‚¯ãƒ©ã‚¹
FRAME_INTERVAL_SEC = 1  # 1ç§’ã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–ã‚Šå‡ºã™

# === åˆæœŸåŒ– ===
os.makedirs(OUTPUT_DIR, exist_ok=True)
model = YOLO(YOLO_MODEL_PATH)

# === å‹•ç”»èª­ã¿è¾¼ã¿ ===
cap = cv2.VideoCapture(VIDEO_PATH)
fps = cap.get(cv2.CAP_PROP_FPS)
frame_interval = int(fps * FRAME_INTERVAL_SEC)

frame_count = 0
save_count = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break

    if frame_count % frame_interval == 0:
        # === YOLOã§ç‰©ä½“æ¤œå‡º ===
        results = model(frame)
        max_area = 0
        best_box = None

        for r in results:
            for box in r.boxes:
                cls_id = int(box.cls)
                label = model.names[cls_id]
                if label == TARGET_CLASS:
                    xyxy = box.xyxy[0].cpu().numpy()
                    x1, y1, x2, y2 = map(int, xyxy)
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area:
                        max_area = area
                        best_box = (x1, y1, x2, y2)

        if best_box:
            x1, y1, x2, y2 = map(int, best_box)
            person_crop = frame[y1:y2, x1:x2]

            # ã‚µã‚¤ã‚ºç¢ºèª
            h, w = person_crop.shape[:2]
            if h >= 10 and w >= 10:
                # ç¸¦2åˆ†å‰²ã€æ¨ª2åˆ†å‰²
                half_h, half_w = h // 2, w // 2
                crops = [
                    person_crop[0:half_h, 0:half_w],      # å·¦ä¸Š
                    person_crop[0:half_h, half_w:w],      # å³ä¸Š
                    person_crop[half_h:h, 0:half_w],      # å·¦ä¸‹
                    person_crop[half_h:h, half_w:w],      # å³ä¸‹
                ]

                for idx, crop_img in enumerate(crops):
                    output_path = os.path.join(OUTPUT_DIR, f"frame{save_count:04d}_part{idx+1}.jpg")
                    cv2.imwrite(output_path, crop_img)

                print(f"âœ… Saved frame{save_count:04d}")
                save_count += 1
            else:
                print(f"âš  å°ã•ã™ãã‚‹cropã‚’ã‚¹ã‚­ãƒƒãƒ— (frame {frame_count})")
        else:
            print(f"âš  No person detected (frame {frame_count})")

    frame_count += 1

cap.release()
print("ğŸ‰ å®Œäº†ï¼")
