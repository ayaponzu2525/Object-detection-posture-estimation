import cv2
import os
import numpy as np
from ultralytics import YOLO

# å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã€ç‰©ä½“æ¤œå‡ºã‚’è¡Œã„ã€æŒ‡å®šã—ãŸãƒ‘ãƒ¼ãƒˆã®ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥ç”»åƒã‚’ä½œæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# === è¨­å®š ===
VIDEO_PATH = r"C:\Users\ayapo\Documents\hightech_local\Object-detection-posture-estimation\movie\input_video.mp4"
OUTPUT_DIR = r"C:\Users\ayapo\Documents\hightech_local\Object-detection-posture-estimation\movie\frames_3"
COLLAGE_OUTPUT_PATH = r"C:\Users\ayapo\Documents\hightech_local\Object-detection-posture-estimation\movie\collage_part4.jpg"
YOLO_MODEL_PATH = "yolov8s.pt"  # ä½¿ç”¨ã™ã‚‹YOLOãƒ¢ãƒ‡ãƒ«
TARGET_CLASS = "person"  # æ¤œå‡ºå¯¾è±¡ã‚¯ãƒ©ã‚¹
FRAME_INTERVAL_SEC = 1  # 1ç§’ã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–ã‚Šå‡ºã™
TARGET_PART = "part4"  # ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥å¯¾è±¡ãƒ‘ãƒ¼ãƒˆ
RESIZE_HEIGHT = 200  # ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥ç”»åƒã®é«˜ã•
MAX_WIDTH = 5000  # ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥ç”»åƒã®æœ€å¤§å¹…ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰

# === åˆæœŸåŒ– ===
os.makedirs(OUTPUT_DIR, exist_ok=True)
model = YOLO(YOLO_MODEL_PATH)

# === å‹•ç”»èª­ã¿è¾¼ã¿ ===
cap = cv2.VideoCapture(VIDEO_PATH)
fps = cap.get(cv2.CAP_PROP_FPS)
frame_interval = int(fps * FRAME_INTERVAL_SEC)

frame_count = 0
save_count = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break

    if frame_count % frame_interval == 0:
        # === YOLOã§ç‰©ä½“æ¤œå‡º ===
        results = model(frame)
        max_area = 0
        best_box = None

        for r in results:
            for box in r.boxes:
                cls_id = int(box.cls)
                label = model.names[cls_id]
                if label == TARGET_CLASS:
                    xyxy = box.xyxy[0].cpu().numpy()
                    x1, y1, x2, y2 = map(int, xyxy)
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area:
                        max_area = area
                        best_box = (x1, y1, x2, y2)

        if best_box:
            x1, y1, x2, y2 = map(int, best_box)
            person_crop = frame[y1:y2, x1:x2]

            # ã‚µã‚¤ã‚ºç¢ºèª
            h, w = person_crop.shape[:2]
            if h >= 10 and w >= 10:
                # ç¸¦2åˆ†å‰²ã€æ¨ª2åˆ†å‰²
                half_h, half_w = h // 2, w // 2
                crops = [
                    person_crop[0:half_h, 0:half_w],      # å·¦ä¸Š
                    person_crop[0:half_h, half_w:w],      # å³ä¸Š
                    person_crop[half_h:h, 0:half_w],      # å·¦ä¸‹
                    person_crop[half_h:h, half_w:w],      # å³ä¸‹
                ]

                for idx, crop_img in enumerate(crops):
                    output_path = os.path.join(OUTPUT_DIR, f"frame{save_count:04d}_part{idx+1}.jpg")
                    cv2.imwrite(output_path, crop_img)

                print(f"âœ… Saved frame{save_count:04d}")
                save_count += 1
            else:
                print(f"âš  å°ã•ã™ãã‚‹cropã‚’ã‚¹ã‚­ãƒƒãƒ— (frame {frame_count})")
        else:
            print(f"âš  No person detected (frame {frame_count})")

    frame_count += 1

cap.release()
print("ğŸ‰ ã‚¯ãƒ­ãƒƒãƒ—å®Œäº†ï¼")

# === ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥ä½œæˆ ===
part_images = sorted([f for f in os.listdir(OUTPUT_DIR) if TARGET_PART in f and f.endswith(".jpg")])
image_list = []

for img_name in part_images:
    img_path = os.path.join(OUTPUT_DIR, img_name)
    img = cv2.imread(img_path)
    if img is not None:
        h, w = img.shape[:2]
        resize_width = int(w * (RESIZE_HEIGHT / h))
        resized_img = cv2.resize(img, (resize_width, RESIZE_HEIGHT))
        image_list.append(resized_img)

if image_list:
    rows = []
    current_row = []
    current_width = 0

    for img in image_list:
        if current_width + img.shape[1] > MAX_WIDTH:
            row = np.hstack(current_row)
            rows.append(row)
            current_row = [img]
            current_width = img.shape[1]
        else:
            current_row.append(img)
            current_width += img.shape[1]

    if current_row:
        row = np.hstack(current_row)
        rows.append(row)

    collage = np.vstack(rows)
    cv2.imwrite(COLLAGE_OUTPUT_PATH, collage)
    print(f"ğŸ‰ ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥ä¿å­˜å®Œäº†: {COLLAGE_OUTPUT_PATH}")
else:
    print("âš  ã‚³ãƒ©ãƒ¼ã‚¸ãƒ¥å¯¾è±¡ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
